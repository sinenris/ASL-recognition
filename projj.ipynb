{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fk1OiQhNRwj-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Functia va returna images, labels\n",
        "\n",
        "#pt training directory, unde structura este de forma asl_alphabet_train/asl_alphabet_train/{label}/{image}\n",
        "def load_images_train(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for idx, label in enumerate(unique_labels):\n",
        "        for file in os.listdir(directory + \"/\" + label):\n",
        "            filepath = directory + \"/\" + label + \"/\" + file\n",
        "            image = cv2.resize(cv2.imread(filepath), (64, 64))\n",
        "            images.append(image)\n",
        "            labels.append(idx)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return(images, labels)\n",
        "\n",
        "#pt testing directory, unde structura este de forma asl_alphabet_test/asl_alphabet_test/{label}_'test.jpg'\n",
        "def load_images_test(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for idx, label in enumerate(unique_labels):\n",
        "        print(directory + \"/\" + label + \"_test\")\n",
        "        image = cv2.resize(cv2.imread(directory + \"/\" + label + \"_test.jpg\"), (64, 64))\n",
        "        images.append(image)\n",
        "        labels.append(idx)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return(images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'nothing', 'space']\n",
            "asl_alphabet_test/asl_alphabet_test/A_test\n",
            "asl_alphabet_test/asl_alphabet_test/B_test\n",
            "asl_alphabet_test/asl_alphabet_test/C_test\n",
            "asl_alphabet_test/asl_alphabet_test/D_test\n",
            "asl_alphabet_test/asl_alphabet_test/E_test\n",
            "asl_alphabet_test/asl_alphabet_test/F_test\n",
            "asl_alphabet_test/asl_alphabet_test/G_test\n",
            "asl_alphabet_test/asl_alphabet_test/H_test\n",
            "asl_alphabet_test/asl_alphabet_test/I_test\n",
            "asl_alphabet_test/asl_alphabet_test/J_test\n",
            "asl_alphabet_test/asl_alphabet_test/K_test\n",
            "asl_alphabet_test/asl_alphabet_test/L_test\n",
            "asl_alphabet_test/asl_alphabet_test/M_test\n",
            "asl_alphabet_test/asl_alphabet_test/N_test\n",
            "asl_alphabet_test/asl_alphabet_test/O_test\n",
            "asl_alphabet_test/asl_alphabet_test/P_test\n",
            "asl_alphabet_test/asl_alphabet_test/Q_test\n",
            "asl_alphabet_test/asl_alphabet_test/R_test\n",
            "asl_alphabet_test/asl_alphabet_test/S_test\n",
            "asl_alphabet_test/asl_alphabet_test/T_test\n",
            "asl_alphabet_test/asl_alphabet_test/U_test\n",
            "asl_alphabet_test/asl_alphabet_test/V_test\n",
            "asl_alphabet_test/asl_alphabet_test/W_test\n",
            "asl_alphabet_test/asl_alphabet_test/X_test\n",
            "asl_alphabet_test/asl_alphabet_test/Y_test\n",
            "asl_alphabet_test/asl_alphabet_test/Z_test\n",
            "asl_alphabet_test/asl_alphabet_test/nothing_test\n",
            "asl_alphabet_test/asl_alphabet_test/space_test\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "train_dir = 'asl_alphabet_train/asl_alphabet_train'\n",
        "eval_dir = 'asl_alphabet_test/asl_alphabet_test'\n",
        "unique_labels = sorted(os.listdir(train_dir))\n",
        "print(unique_labels)\n",
        "images, labels = load_images_train(directory = train_dir)\n",
        "img_eval, lbl_eval = load_images_test(directory = eval_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of labels:  28\n",
            "Training img number:  75600\n",
            "Testing img number:  8400\n",
            "Eval img number: 28\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#train data & test data\n",
        "img_train, img_test, lbl_train, lbl_test = train_test_split(images, labels, test_size = 0.1, stratify = labels)\n",
        "\n",
        "print(\"Number of labels: \", len(unique_labels))\n",
        "print(\"Training img number: \" , len(img_train))\n",
        "print(\"Testing img number: \", len(img_test))\n",
        "print(\"Eval img number:\", len(img_eval))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n"
          ]
        }
      ],
      "source": [
        "#one hot enconding using to_categorical.\n",
        "import tensorflow as tf\n",
        "from keras import utils as np_utils\n",
        "\n",
        "lbl_train = tf.keras.utils.to_categorical(lbl_train)\n",
        "lbl_test = tf.keras.utils.to_categorical(lbl_test)\n",
        "lbl_eval = tf.keras.utils.to_categorical(lbl_eval)\n",
        "#print(lbl_train[1000])\n",
        "print(len(lbl_train[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[0.8980392  0.00392157 0.00784314]\n",
            "  [0.74509805 0.04313726 0.05098039]\n",
            "  [0.7372549  0.04705882 0.04705882]\n",
            "  ...\n",
            "  [0.7372549  0.04313726 0.04313726]\n",
            "  [0.7529412  0.03529412 0.05490196]\n",
            "  [0.84313726 0.04705882 0.0627451 ]]\n",
            "\n",
            " [[0.7490196  0.05098039 0.04705882]\n",
            "  [0.4117647  0.43137255 0.38431373]\n",
            "  [0.40784314 0.42745098 0.39607844]\n",
            "  ...\n",
            "  [0.18431373 0.1882353  0.20784314]\n",
            "  [0.23921569 0.1764706  0.21960784]\n",
            "  [0.49019608 0.17254902 0.19607843]]\n",
            "\n",
            " [[0.75686276 0.06666667 0.04313726]\n",
            "  [0.5921569  0.6117647  0.5294118 ]\n",
            "  [0.5803922  0.5882353  0.5019608 ]\n",
            "  ...\n",
            "  [0.23529412 0.24313726 0.28235295]\n",
            "  [0.24705882 0.23529412 0.2784314 ]\n",
            "  [0.5176471  0.2        0.22745098]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.74509805 0.02352941 0.00784314]\n",
            "  [0.14117648 0.08235294 0.0627451 ]\n",
            "  [0.16078432 0.09803922 0.09411765]\n",
            "  ...\n",
            "  [0.09411765 0.19607843 0.3137255 ]\n",
            "  [0.11372549 0.18431373 0.29803923]\n",
            "  [0.42745098 0.16862746 0.25490198]]\n",
            "\n",
            " [[0.7647059  0.04313726 0.03137255]\n",
            "  [0.16470589 0.11372549 0.10980392]\n",
            "  [0.16470589 0.11764706 0.10588235]\n",
            "  ...\n",
            "  [0.14117648 0.21960784 0.30588236]\n",
            "  [0.16078432 0.19215687 0.28235295]\n",
            "  [0.43137255 0.16078432 0.23137255]]\n",
            "\n",
            " [[0.8156863  0.01568628 0.01568628]\n",
            "  [0.34509805 0.02352941 0.03137255]\n",
            "  [0.3647059  0.02745098 0.01960784]\n",
            "  ...\n",
            "  [0.4509804  0.1882353  0.25490198]\n",
            "  [0.44705883 0.16862746 0.22352941]\n",
            "  [0.627451   0.13333334 0.18039216]]]\n"
          ]
        }
      ],
      "source": [
        "#data nnorm\n",
        "img_train = img_train.astype('float32')/255.0\n",
        "img_test = img_test.astype('float32')/255.0\n",
        "img_eval = img_eval.astype('float32')/255.0\n",
        "print(img_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 64, 64, 64)        4864      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 28)                458780    \n",
            "=================================================================\n",
            "Total params: 463,644\n",
            "Trainable params: 463,644\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "756/756 [==============================] - 170s 223ms/step - loss: 1.4987 - accuracy: 0.5688 - recall_2: 0.3667\n",
            "Epoch 2/2\n",
            "756/756 [==============================] - 166s 219ms/step - loss: 0.5776 - accuracy: 0.8245 - recall_2: 0.7287\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu', \n",
        "                 input_shape = (64, 64, 3)))\n",
        "model.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(28, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy',tf.keras.metrics.Recall()])\n",
        "hist = model.fit(img_train, lbl_train, epochs = 2, batch_size = 100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 64, 64, 64)        4864      \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 64, 64, 64)        102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 28)                458780    \n",
            "=================================================================\n",
            "Total params: 566,108\n",
            "Trainable params: 566,108\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "756/756 [==============================] - 1502s 2s/step - loss: 1.0650 - accuracy: 0.6814 - recall_3: 0.5743\n",
            "Epoch 2/2\n",
            "756/756 [==============================] - 1520s 2s/step - loss: 0.2460 - accuracy: 0.9215 - recall_3: 0.8988\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu', \n",
        "                 input_shape = (64, 64, 3)))\n",
        "model2.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model2.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(28, activation='softmax'))\n",
        "model2.summary()\n",
        "model2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy',tf.keras.metrics.Recall()])\n",
        "hist2 = model2.fit(img_train, lbl_train, epochs = 2, batch_size = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 64, 64, 64)        4864      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 64, 64, 64)        102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 128)       204928    \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 128)       409728    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 28)                57372     \n",
            "=================================================================\n",
            "Total params: 779,356\n",
            "Trainable params: 779,356\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "756/756 [==============================] - 1892s 3s/step - loss: 1.2301 - accuracy: 0.6227 - recall_4: 0.5360\n",
            "Epoch 2/2\n",
            "756/756 [==============================] - 1846s 2s/step - loss: 0.1736 - accuracy: 0.9411 - recall_4: 0.9282\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu', \n",
        "                 input_shape = (64, 64, 3)))\n",
        "model3.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Conv2D(filters = 128 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model3.add(Conv2D(filters = 128 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(28, activation='softmax'))\n",
        "\n",
        "model3.summary()\n",
        "\n",
        "model3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy',tf.keras.metrics.Recall()])\n",
        "hist = model3.fit(img_train, lbl_train, epochs = 2, batch_size = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 64, 64, 64)        4864      \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 64, 64, 64)        102464    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 128)       204928    \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 16, 16, 128)       409728    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 28)                57372     \n",
            "=================================================================\n",
            "Total params: 779,356\n",
            "Trainable params: 779,356\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "756/756 [==============================] - 1871s 2s/step - loss: 1.0983 - accuracy: 0.6654 - recall_6: 0.5847\n",
            "Epoch 2/5\n",
            "756/756 [==============================] - 1894s 3s/step - loss: 0.1413 - accuracy: 0.9522 - recall_6: 0.9429\n",
            "Epoch 3/5\n",
            "756/756 [==============================] - 1967s 3s/step - loss: 0.0777 - accuracy: 0.9735 - recall_6: 0.9703\n",
            "Epoch 4/5\n",
            "394/756 [==============>...............] - ETA: 15:45 - loss: 0.0629 - accuracy: 0.9802 - recall_6: 0.9780"
          ]
        }
      ],
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu', \n",
        "                 input_shape = (64, 64, 3)))\n",
        "model3.add(Conv2D(filters = 64, kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Conv2D(filters = 128 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model3.add(Conv2D(filters = 128 , kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "model3.add(MaxPooling2D(pool_size = (4, 4)))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(28, activation='softmax'))\n",
        "\n",
        "model3.summary()\n",
        "\n",
        "model3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy',tf.keras.metrics.Recall()])\n",
        "hist = model3.fit(img_train, lbl_train, epochs = 5, batch_size = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('md1.h5')\n",
        "model2.save('md2.h5')\n",
        "#score = model.evaluate(x = img_test[:50], y = lbl_test[:50], verbose = 0)\n",
        "#print('Accuracy for test images:', round(score[1]*100, 3), '%')\n",
        "\n",
        "#score = model.evaluate(x = img_eval, y = lbl_eval, verbose = 0)\n",
        "#print('Accuracy for evaluation images:', round(score[1]*100, 3), '%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "P\n",
            "Y\n",
            "P\n",
            "P\n",
            "P\n",
            "P\n",
            "Y\n",
            "P\n",
            "P\n",
            "P\n",
            "T\n",
            "P\n",
            "P\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "T\n",
            "T\n",
            "T\n",
            "T\n",
            "T\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n",
            "Y\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model('md.h5')\n",
        "cap = cv2.VideoCapture(0)\n",
        "unique_labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'nothing', 'space']\n",
        "while(True):\n",
        "      \n",
        "    # Capture frames in the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "\n",
        "    ################################\n",
        "    #frame = cv2.flip(frame,1)\n",
        "  \n",
        "    #define roi\n",
        "    roi = frame[100:400, 320:620]\n",
        "    cv2.imshow('roi',roi)\n",
        "\n",
        "    # describe the type of font\n",
        "    # to be used.\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    # Use putText() method for\n",
        "    # inserting text on video\n",
        "    cv2.rectangle(frame, (320, 100), (620, 400), (0, 0, 0), 0)\n",
        "    image = cv2.resize(roi, (64, 64))\n",
        "    to_send = np.array(image).astype('float32')/255.0\n",
        "    to_send = to_send.reshape(-1, 64, 64, 3)\n",
        "    string = unique_labels[np.argmax(model.predict(to_send), axis=1)[0]]\n",
        "    print(string)\n",
        "    cv2.putText(frame, \n",
        "                string, \n",
        "                (50, 50), \n",
        "                font, 1, \n",
        "                (0, 255, 255), \n",
        "                2, \n",
        "                cv2.LINE_4)\n",
        "     # Display the resulting frame\n",
        "    cv2.imshow('video', frame)\n",
        "    # creating 'q' as the quit \n",
        "    # button for the video\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "  \n",
        "# release the cap object\n",
        "cap.release()\n",
        "# close all windows\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of Computer Vision and Deep Learning - Laboratory 4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
